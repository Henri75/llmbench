{
    "servers": {
        "Server1": {"base_url": "http://localhost:11435/v1", "label": "CustomMLX"},
        "Server2": {"base_url": "http://localhost:11434/v1", "label": "CustomOllama"}
    },
    "benchmarks": [
        {
            "num_servers": 2,
            "server_combo": "Server1+Server2",
            "models": {
                "Server1": "mlx-community/Llama-3.2-1B-Instruct-4bit",
                "Server2": "llama3.2:1b"
            },
            "custom_prompt": "Write a 200-word story",
            "num_repeats": 1
        },
        {
            "num_servers": 2,
            "server_combo": "Server1+Server2",
            "model_name": "llama 3.2 1B Q4",
            "custom_prompt": "Summarize AI advancements in 300 words",
            "num_repeats": 2
        }
    ]
}