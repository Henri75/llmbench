{
  "servers": {
    "Server1": {
      "base_url": "http://localhost:11435/v1",
      "model": "mlx-community/Llama-3.2-3B-Instruct-4bit",
      "label": "MLX",
      "api_call": "openai",
      "status": "up"
    },
    "Server2": {
      "base_url": "http://localhost:11434/v1",
      "model": "llama3.2",
      "label": "Ollama",
      "api_call": "openai",
      "status": "up"
    },
    "Server3": {
      "base_url": "http://localhost:11436/v1",
      "model": "some-model",
      "label": "LM Studios",
      "api_call": "openai",
      "status": "up"
    },
    "Server4": {
      "base_url": "http://localhost:11437/v1",
      "model": "another-model",
      "label": "NewServer",
      "api_call": null,
      "status": "down"
    },
    "TEST Server": {
      "base_url": "http://localhost:11436/v1",
      "label": "testing",
      "status": "down",
      "api_call": null
    }
  }
}